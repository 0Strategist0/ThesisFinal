# Thesis Final
*May 12, 2024*

___

This is a final version of the important code for Kye's Honours Thesis. The thesis itself is linked above, and contains most of the high-level information as to what's happening in this code. The rest I will explain here. 

**P.S.** I didn't notice this until after finishing my thesis, but somehow I got one neural network that trained faaaaaar better than the others. I couldn't reproduce it, and it had worse mean squared error than my "best" neural network from the thesis, but its confidence intervals contained the true values within 1 standard deviation of the expected number of times. I used the reciprocal loss for that training, with batch normalization, and 7 layers of 70 neurons. However, as I mentioned, I tried reproducing it once I noticed that it was performing better, and I couldn't get an equally good one, so maybe it was lucky? Maybe training for 50000-100000 epochs with those same settings would help?

___

## Important

This directory contains all the most important code that should be working as-is. 

### requirements.txt

This file should contain all the python requirements to run the code in the files. There's probably some extra stuff that's unneeded in this file, but it's what my virtual environment looked like at the end of my work. Use `pip install -r PATH_TO_REQUIREMENTS.TXT` to install all of these packages. They should all be able to run on Compute Canada's Cedar cluster. 

### training.py

This is the main script used to train the neural networks for the thesis. Settings for the training all all defined as constants at the start of the `main()` function. Here is a description of each setting. 

- PATH_TO_DATA: This is the path to the data pickle file generated by `create_pkl_file.py` in the DataFormatting directory.
- C_VALUE_PREFIX: The prefix for the columns in the above data file which contain values of the Wilson Coefficients. 
- KINEMATIC_COLUMNS: A numpy array of column indices containing kinematic variables. 
- RANDOMIZE_DATA: Whether to randomize the order of the data being fed into the network for training. 
- TRAINING_SLICE: The slice of data to use for training (so you can reserve some amount as testing data). 
- BATCH_SIZE: The size of each mini-batch for the training. 
- COEF_VALUES: Which values of the Wilson Coefficients to use for the training. Must have corresponding columns in the data file. 
- HIDDEN_LAYERS: A tuple containing the number of neurons in each layer of the network. For example, (3, 4, 5) would generate a neural network with 3 layers of 3, 4, and 5 neurons respectively. 
- ACTIVATION: The Keras name of the activation function to use on all the neurons in the hidden layers. 
- DROPOUT_FRAC: The fraction of neurons to use in dropout regularization. 
- BATCH_NORMALIZATION: Whether to enable batch normalization between hidden layers. 
- OPTIMIZER: An Adam optimizer object to use when training the neural network. 
- EPOCHS: How many epochs to use when training the neural network. 
- EARLY_STOPPING: Whether to stop the training early if loss stops decreasing.
- PATIENCE: The number of epochs to wait once loss stops decreasing before stopping. 
- MIN_DELTA: If the loss decreases by more than this value, early stopping doesn't trigger. 
- REDUCE_LR_ON_PLATEAU: Whether to reduce the learning rate while on a plateau.
- VALIDATION_SPLIT: The fraction of data to use as validation data. 
- CHECKPOINT_PATH: The path to the checkpoint directory
- CHECKPOINT_PERIOD: The number of epochs between each saved checkpoint. 
- SAVE_DIRECTORY: The directory in which to save the final networks. 
- NETWORK_NAME: The name with which to save the networks.

### all_training_utils

This is just a utility file for training the neural networks. Some of the functions in there are from very early on and don't get used anymore, though they all have decent comment documentation, so feel free to read through them. 

### comparing_models

This is a file used to plot confidence intervals generated by the neural networks to test and compare them. Again, some settings are defined at the top of the `main()` function. Here is a description of each. 

- P_VALUE: The confidence level of the confidence intervals to generate.
- C: The Wilson Coefficient value used to generate the data
- TEST_DATA_PATH: Path to testing data created with the `generate_test_data.py` script in the DataFormatting directory.
- TEST_WEIGHTS_PATH: Path to testing weights created the same way.
- MODEL_DIRECTORY: The directory containing the model.
- TOTAL_DATA_PATH: The path to the entire dataset used to train the neural network and generate the test data. 
- NAME: The name to use for saving the images.
- XLABEL: The name of the plot x label. 
- EXTRA_PLOT_WIDTH: Plot formatting.
- PLOT_SHRINK: Plot formatting.

___

## DataFormatting

This directory has some files I used to format data. I didn't really make these with code cleanliness or maintainability in mind, so I can't 100% guarantee they'll work for you. Also, don't judge me on how this code looks lol. I use constants as variables in some of these scripts. 

### create_pkl_file.py

This should in principle take a root file and spit out a pickle file that can be used to train a network. Settings are the constants at the start of the `main()` function like usual. They're kind of self-explanatory here. 

### generate_test_data.py

This should take one of those pickle files generated by the previous script and produce some number of fake collision datasets, as described in the thesis **Data Generation** section. The for loop is just to produce multiple datasets. You can remove it if you only want 1. 

### make_smaller_pkl.py

Takes a dataset generated by `create_pkl_file.py` and uniformly samples from it to make a smaller dataset. Useful for testing the networks sometimes. This is how I made the **Proof of Concept** in my thesis. 

___

That's everything. If you have questions, feel free to get in contact with me. My email is `kyeemondwork@gmail.com`, or you can talk to me on Skype or via Bernd if you want.
